{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of concept\n",
    "## Concensiousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from mne.decoding import CSP\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from c:\\Users\\maxim\\OneDrive\\Documents\\2IA3A\\man_machine_interaction\\poc_concensiousness\\data\\Subject_11_H_AEP_Run_01.set...\n",
      "Not setting metadata\n",
      "480 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "Extracting parameters from c:\\Users\\maxim\\OneDrive\\Documents\\2IA3A\\man_machine_interaction\\poc_concensiousness\\data\\Subject_11_H_AEP_Run_02.set...\n",
      "Not setting metadata\n",
      "480 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: FCz, C3, Cz, C4, CP1, CPZ, CP2, PZ\n",
      " chs: 8 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 8 items (8 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 128.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 8\n",
      " projs: []\n",
      " sfreq: 256.0 Hz\n",
      ">\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: FCz, C3, Cz, C4, CP1, CPZ, CP2, PZ\n",
      " chs: 8 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 8 items (8 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 128.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 8\n",
      " projs: []\n",
      " sfreq: 256.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "data_loo = mne.io.read_epochs_eeglab(input_fname = \"./data/Subject_11_H_AEP_Run_01.set\")\n",
    "data_tst = mne.io.read_epochs_eeglab(input_fname = \"./data/Subject_11_H_AEP_Run_02.set\")\n",
    "\n",
    "print(data_loo.info)\n",
    "print(data_tst.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data and reduce them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank=None\n",
      "    Using tolerance 1.7e-05 (2.2e-16 eps * 8 dim * 9.4e+09  max singular value)\n",
      "    Estimated rank (mag): 8\n",
      "    MAG: rank 8 computed from 8 data channels with 0 projectors\n",
      "Reducing data rank from 8 -> 8\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 6.9e-06 (2.2e-16 eps * 8 dim * 3.9e+09  max singular value)\n",
      "    Estimated rank (mag): 8\n",
      "    MAG: rank 8 computed from 8 data channels with 0 projectors\n",
      "Reducing data rank from 8 -> 8\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "[[-1.2914822  -0.88632756 -0.51320967 -1.92866471 -1.53036937 -0.805537  ]\n",
      " [-0.89208774 -0.35877956 -1.4335205  -1.70896103 -1.26420468  0.06993202]\n",
      " [-1.28082043 -1.83111204 -1.7105161   0.31088006 -1.58945684 -2.07868669]\n",
      " ...\n",
      " [-0.04988749 -0.4538856  -1.01266451 -1.21901488 -1.06053201 -0.01805965]\n",
      " [ 0.7344182  -0.5214834  -0.56665054  0.05419206 -0.80953653 -1.49719722]\n",
      " [-1.56027926 -0.66720475 -0.7227454  -0.80674491 -0.04341267 -1.77096568]]\n"
     ]
    }
   ],
   "source": [
    "t = data_loo.times\n",
    "x = data_loo.get_data()\n",
    "y = data_loo.events[:,2]\n",
    "csp = CSP(n_components=6, transform_into='average_power')\n",
    "\n",
    "x_csp_average = csp.fit_transform(x, y)\n",
    "\n",
    "print(x_csp_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y - 1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.291482</td>\n",
       "      <td>-0.886328</td>\n",
       "      <td>-0.513210</td>\n",
       "      <td>-1.928665</td>\n",
       "      <td>-1.530369</td>\n",
       "      <td>-0.805537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.892088</td>\n",
       "      <td>-0.358780</td>\n",
       "      <td>-1.433521</td>\n",
       "      <td>-1.708961</td>\n",
       "      <td>-1.264205</td>\n",
       "      <td>0.069932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.280820</td>\n",
       "      <td>-1.831112</td>\n",
       "      <td>-1.710516</td>\n",
       "      <td>0.310880</td>\n",
       "      <td>-1.589457</td>\n",
       "      <td>-2.078687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.129464</td>\n",
       "      <td>-0.964238</td>\n",
       "      <td>-1.835661</td>\n",
       "      <td>-1.822631</td>\n",
       "      <td>-2.110521</td>\n",
       "      <td>-0.088511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.592715</td>\n",
       "      <td>-0.540658</td>\n",
       "      <td>-1.404375</td>\n",
       "      <td>-0.711744</td>\n",
       "      <td>-1.574846</td>\n",
       "      <td>-0.282342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-1.597987</td>\n",
       "      <td>-0.666707</td>\n",
       "      <td>-1.505596</td>\n",
       "      <td>0.047970</td>\n",
       "      <td>-0.838545</td>\n",
       "      <td>-1.707438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.084863</td>\n",
       "      <td>-1.426108</td>\n",
       "      <td>-1.131338</td>\n",
       "      <td>-0.817489</td>\n",
       "      <td>-0.749081</td>\n",
       "      <td>-1.787761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>-0.049887</td>\n",
       "      <td>-0.453886</td>\n",
       "      <td>-1.012665</td>\n",
       "      <td>-1.219015</td>\n",
       "      <td>-1.060532</td>\n",
       "      <td>-0.018060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.734418</td>\n",
       "      <td>-0.521483</td>\n",
       "      <td>-0.566651</td>\n",
       "      <td>0.054192</td>\n",
       "      <td>-0.809537</td>\n",
       "      <td>-1.497197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-1.560279</td>\n",
       "      <td>-0.667205</td>\n",
       "      <td>-0.722745</td>\n",
       "      <td>-0.806745</td>\n",
       "      <td>-0.043413</td>\n",
       "      <td>-1.770966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5\n",
       "0   -1.291482 -0.886328 -0.513210 -1.928665 -1.530369 -0.805537\n",
       "1   -0.892088 -0.358780 -1.433521 -1.708961 -1.264205  0.069932\n",
       "2   -1.280820 -1.831112 -1.710516  0.310880 -1.589457 -2.078687\n",
       "3   -0.129464 -0.964238 -1.835661 -1.822631 -2.110521 -0.088511\n",
       "4   -0.592715 -0.540658 -1.404375 -0.711744 -1.574846 -0.282342\n",
       "..        ...       ...       ...       ...       ...       ...\n",
       "475 -1.597987 -0.666707 -1.505596  0.047970 -0.838545 -1.707438\n",
       "476  0.084863 -1.426108 -1.131338 -0.817489 -0.749081 -1.787761\n",
       "477 -0.049887 -0.453886 -1.012665 -1.219015 -1.060532 -0.018060\n",
       "478  0.734418 -0.521483 -0.566651  0.054192 -0.809537 -1.497197\n",
       "479 -1.560279 -0.667205 -0.722745 -0.806745 -0.043413 -1.770966\n",
       "\n",
       "[480 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = pd.DataFrame(x_csp_average)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.30304885, 0.37799954, 0.43699574, 0.35299778, 0.34300232,\n",
       "        0.52999926, 0.45893145, 0.36904097, 0.62798452, 0.61294866,\n",
       "        0.65994835, 0.4279716 , 0.59804392, 0.60904598, 0.60295558,\n",
       "        0.60705352, 0.60700178, 0.49405456, 0.52899575, 0.60095787,\n",
       "        0.61213279, 0.55299664, 0.53399706, 0.54799628, 0.53096437,\n",
       "        0.55400324, 0.56799364, 0.53300166, 0.50098228, 0.21199942,\n",
       "        0.2159965 , 0.15800357, 0.15803051, 0.16200328, 0.19100404,\n",
       "        0.18599772, 0.17397189, 0.16299629, 0.17699957, 0.16200185,\n",
       "        0.16003537, 0.15900087, 0.170995  , 0.17102981, 0.16702938,\n",
       "        0.21103311, 0.18303037, 0.16499972, 0.16303587, 0.17496753,\n",
       "        0.17303658, 0.16303062, 0.16199851, 0.15700865, 0.16100121,\n",
       "        0.16299868, 0.16996193, 0.15796685, 0.16302848, 0.16799831,\n",
       "        0.17400384, 0.16596627, 0.19200158, 0.19099808, 0.18402648,\n",
       "        0.15700364, 0.15996718, 0.16299224, 0.16300035, 0.16196895,\n",
       "        0.17800164, 0.17003059, 0.17000175, 0.16099358, 0.16100359,\n",
       "        0.18096495, 0.18499684, 0.16503191, 0.17800331, 0.16902781,\n",
       "        0.16597199, 0.16500425, 0.16099882, 0.1849649 , 0.19199562,\n",
       "        0.18200088, 0.17900753, 0.17596483, 0.17699957, 0.1859653 ,\n",
       "        0.16402364, 0.15700126, 0.1609695 , 0.1620307 , 0.16499925,\n",
       "        0.15803099, 0.16203189, 0.16196632, 0.15800166, 0.15999627,\n",
       "        0.15896773, 0.16003132, 0.16596699, 0.16696596, 0.16000557,\n",
       "        0.16503382, 0.18900251, 0.18299866, 0.15699768, 0.16200137,\n",
       "        0.15596557, 0.15899444, 0.16600347, 0.1740315 , 0.16302967,\n",
       "        0.16297364, 0.16003203, 0.17102957, 0.18803144, 0.20100045,\n",
       "        0.19500089, 0.19100261, 0.21496511, 0.17296982, 0.17599201,\n",
       "        0.1629951 , 0.16299701, 0.16100287, 0.16303325, 0.17697334,\n",
       "        0.16100073, 0.16296816, 0.15999746, 0.16000533, 0.1650281 ,\n",
       "        0.19800282, 0.15600204, 0.16402793, 0.1660018 , 0.19396901,\n",
       "        0.19000292, 0.16896844, 0.16203475, 0.15700388, 0.16402745,\n",
       "        0.16299915, 0.18700385, 0.19299984, 0.16500163, 0.16103673,\n",
       "        0.16200066, 0.15903521, 0.16996813, 0.16199923, 0.1569984 ,\n",
       "        0.16196609, 0.16902113, 0.15899777, 0.1570313 , 0.16199756,\n",
       "        0.16200447, 0.16296744, 0.306036  , 0.44299817, 0.59196377,\n",
       "        0.62304664, 0.61102438, 0.59205532, 0.60796857, 0.60100412,\n",
       "        0.30602932, 0.30599308, 0.3179996 , 0.35800052, 0.35500693,\n",
       "        0.32900071, 0.33003187, 0.30204463, 0.2339983 , 0.32800579,\n",
       "        0.20403171, 0.16100025, 0.1639967 , 0.16703367, 0.17000318,\n",
       "        0.16203499, 0.16499472, 0.21899891, 0.31899595, 0.39297605,\n",
       "        0.28199911, 0.30300283, 0.37400556, 0.39199543, 0.31500387,\n",
       "        0.35401058, 0.47302485, 0.32502127, 0.62599897, 0.58897901,\n",
       "        0.62700558, 0.59400105, 0.56699014, 0.53200841, 0.62998962,\n",
       "        0.39798951, 0.59004736, 0.60199523, 0.62504506, 0.48095036,\n",
       "        0.59994578, 0.61800694, 0.54804802, 0.59194732, 0.55298638,\n",
       "        0.55099559, 0.54699779, 0.54000425, 0.54499841, 0.60398531,\n",
       "        0.24300075, 0.52300143, 0.56700015, 0.50200057, 0.52499485,\n",
       "        0.53800821, 0.55699801, 0.29498291, 0.57500052, 0.5859828 ,\n",
       "        0.38396692, 0.53702474, 0.50493813, 0.48807502, 0.50197148,\n",
       "        0.55094409, 0.56205058, 0.54100204, 0.60799575, 0.24798441,\n",
       "        0.27996564, 0.2740283 , 0.27400494, 0.27203131, 0.2340343 ,\n",
       "        0.1770308 , 0.16796875, 0.17600203, 0.16999984, 0.17800045,\n",
       "        0.24299741, 0.28600597, 0.58200097, 0.55701256, 0.54702878,\n",
       "        0.54703522, 0.52695966, 0.53595257, 0.38295913, 0.53699636,\n",
       "        0.54395008, 0.53304744, 0.53694892, 0.55899167, 0.56899047,\n",
       "        0.57494593, 0.52199078, 0.5830133 , 0.55103588, 0.53705478,\n",
       "        0.46998525, 0.23196721, 0.23097348, 0.21400142, 0.21297908,\n",
       "        0.22600412, 0.15999603, 0.1630311 , 0.16400099, 0.15800047,\n",
       "        0.15799928, 0.15799689, 0.16800022, 0.16599965, 0.1640029 ,\n",
       "        0.16996598, 0.18299985, 0.15803933, 0.16896605, 0.16300011,\n",
       "        0.15700269, 0.16099691, 0.15699744, 0.16000223, 0.15896535,\n",
       "        0.17002797, 0.17303228, 0.16903257, 0.15700054, 0.16299725,\n",
       "        0.15996981, 0.16401172, 0.15799832, 0.19399786, 0.18602991,\n",
       "        0.17796421, 0.16996861, 0.16403508, 0.1639998 , 0.16599703,\n",
       "        0.16400576, 0.17097497, 0.18097258, 0.19599986, 0.19503903,\n",
       "        0.18899655, 0.20600367, 0.19400406, 0.21199751, 0.17102408,\n",
       "        0.16300249, 0.1799655 , 0.17002487, 0.15697169, 0.18603373,\n",
       "        0.16499281, 0.15599561, 0.15703321, 0.16397262, 0.16202497,\n",
       "        0.15900421, 0.16400552, 0.15999675, 0.15700388, 0.16099572,\n",
       "        0.16303062, 0.16096568, 0.16099858, 0.15499735, 0.17903519,\n",
       "        0.16203356, 0.16299796, 0.18703389, 0.1599977 , 0.15899801,\n",
       "        0.16399741, 0.16197348, 0.20400071, 0.15899491, 0.15696883,\n",
       "        0.16399717, 0.17102575, 0.17500043, 0.17196774, 0.16100287,\n",
       "        0.15899849, 0.15897012, 0.16200352, 0.16900086, 0.19196439,\n",
       "        0.15903234, 0.19500661, 0.16299629, 0.16303229, 0.15899277,\n",
       "        0.16799712, 0.16499686, 0.17700386, 0.17000103, 0.1589973 ,\n",
       "        0.17496824, 0.18202329, 0.15899897, 0.16396546, 0.1659956 ,\n",
       "        0.15900183, 0.16500211, 0.16200137, 0.16798854, 0.16400313,\n",
       "        0.16396832, 0.178967  , 0.16596532, 0.15900755, 0.16097164,\n",
       "        0.16202831, 0.16699648, 0.16400504, 0.16100121, 0.1590271 ,\n",
       "        0.16196513, 0.1570363 , 0.16200686, 0.15900016, 0.16203308,\n",
       "        0.156039  , 0.1569953 , 0.16896963, 0.16299653, 0.16400313,\n",
       "        0.1940341 , 0.17003131, 0.18697119, 0.18503237, 0.15996552,\n",
       "        0.16303158, 0.16200161, 0.17097545, 0.16799212, 0.16996694,\n",
       "        0.16096973, 0.16103268, 0.15900469, 0.1630044 , 0.16800451,\n",
       "        0.18996572, 0.15703702, 0.16296697, 0.95733476, 0.30096865,\n",
       "        0.1989975 , 0.20103598, 0.20203567, 0.17099977, 0.16296577,\n",
       "        0.16299844, 0.18100023, 0.16202831, 0.16100144, 0.16303039,\n",
       "        0.16099668, 0.16699529, 0.16203141, 0.17903018, 0.16898608,\n",
       "        0.17000461, 0.16799951, 0.169034  , 0.17199802, 0.1599648 ,\n",
       "        0.16299987, 0.16600251, 0.15799665, 0.16603398, 0.16596389,\n",
       "        0.1730082 , 0.15700054, 0.16300488, 0.16903424, 0.17596292,\n",
       "        0.16499543, 0.1790309 , 0.17497897, 0.16396689, 0.16999865,\n",
       "        0.1840024 , 0.16799164, 0.15902925, 0.17000246, 0.16697168,\n",
       "        0.15899897, 0.15999532, 0.16103196, 0.15800071, 0.16296935,\n",
       "        0.1610322 , 0.18203402, 0.19796205, 0.16002917, 0.19696951,\n",
       "        0.17803073, 0.16503215, 0.16596675, 0.18897462, 0.16099548,\n",
       "        0.16103077, 0.15899849, 0.15800118, 0.1630044 , 0.18103456]),\n",
       " 'score_time': array([0.01995373, 0.02199769, 0.01800132, 0.02199459, 0.01599336,\n",
       "        0.0370307 , 0.0190022 , 0.03996468, 0.04805875, 0.03705239,\n",
       "        0.04300284, 0.03899527, 0.03596282, 0.03694868, 0.03305125,\n",
       "        0.03695202, 0.03400898, 0.03494287, 0.04003906, 0.03405476,\n",
       "        0.03101134, 0.03200698, 0.0320065 , 0.03499627, 0.03498721,\n",
       "        0.03199792, 0.03905654, 0.03300834, 0.01599884, 0.01300168,\n",
       "        0.01100016, 0.00899959, 0.00899887, 0.00999475, 0.0109694 ,\n",
       "        0.01103115, 0.00999784, 0.01000071, 0.01199961, 0.00899982,\n",
       "        0.00996161, 0.01000381, 0.01000166, 0.00900531, 0.00997043,\n",
       "        0.01296926, 0.00896525, 0.00899649, 0.00899982, 0.0159955 ,\n",
       "        0.00996685, 0.0089705 , 0.00999641, 0.00899553, 0.01099873,\n",
       "        0.01003695, 0.00899911, 0.01100087, 0.00897121, 0.00999808,\n",
       "        0.01003051, 0.00999904, 0.01099706, 0.01100469, 0.01000023,\n",
       "        0.00899982, 0.01000237, 0.00900149, 0.01003265, 0.01103067,\n",
       "        0.01096678, 0.00899959, 0.01000261, 0.01097131, 0.0100317 ,\n",
       "        0.01003504, 0.01397133, 0.01196432, 0.00999951, 0.0090065 ,\n",
       "        0.01002455, 0.01000071, 0.0100019 , 0.01303124, 0.01200056,\n",
       "        0.00998831, 0.01200461, 0.01000166, 0.00999928, 0.01200747,\n",
       "        0.00900912, 0.00999808, 0.0090034 , 0.0089972 , 0.01000047,\n",
       "        0.00899649, 0.01000094, 0.00999999, 0.01003361, 0.00900388,\n",
       "        0.01000214, 0.01000118, 0.01003623, 0.01099753, 0.00999403,\n",
       "        0.00996661, 0.01203179, 0.00900078, 0.00900054, 0.01000237,\n",
       "        0.00900173, 0.01097012, 0.00999975, 0.00996351, 0.00999904,\n",
       "        0.00999928, 0.009969  , 0.01097226, 0.01596403, 0.01200414,\n",
       "        0.01103067, 0.01096773, 0.01003289, 0.01003456, 0.01097345,\n",
       "        0.01003432, 0.00997043, 0.01299715, 0.00899696, 0.01002955,\n",
       "        0.00996828, 0.01003146, 0.01096869, 0.0099988 , 0.00999832,\n",
       "        0.01096892, 0.00899982, 0.00900006, 0.01000142, 0.0110271 ,\n",
       "        0.00999212, 0.01000428, 0.00900006, 0.01096892, 0.00900102,\n",
       "        0.01100039, 0.01099944, 0.01197076, 0.00999594, 0.00896287,\n",
       "        0.00899935, 0.00999904, 0.0099988 , 0.01003337, 0.01000452,\n",
       "        0.01099825, 0.00901389, 0.01000094, 0.009969  , 0.01002908,\n",
       "        0.00899959, 0.01500249, 0.01699758, 0.03405142, 0.04500389,\n",
       "        0.03794765, 0.0399611 , 0.04995704, 0.04205108, 0.04599404,\n",
       "        0.02197027, 0.01800561, 0.01899743, 0.01500201, 0.01496649,\n",
       "        0.0180037 , 0.01896787, 0.0169549 , 0.01603293, 0.01995945,\n",
       "        0.01096702, 0.01003027, 0.00896549, 0.00899696, 0.00996637,\n",
       "        0.01097155, 0.01000428, 0.01600623, 0.02000427, 0.02400208,\n",
       "        0.01700044, 0.02600026, 0.05199194, 0.01800013, 0.01299381,\n",
       "        0.0429945 , 0.01799917, 0.03804064, 0.04001808, 0.03997159,\n",
       "        0.03499651, 0.03698897, 0.01300168, 0.03700924, 0.04300857,\n",
       "        0.03800011, 0.03696251, 0.03899646, 0.04099321, 0.04404736,\n",
       "        0.04300332, 0.02904749, 0.0309999 , 0.03305411, 0.031003  ,\n",
       "        0.03600407, 0.03299856, 0.03905606, 0.04301357, 0.02200389,\n",
       "        0.03200245, 0.03405643, 0.03200006, 0.03100824, 0.0360024 ,\n",
       "        0.03904772, 0.04300213, 0.04000688, 0.03900957, 0.02204227,\n",
       "        0.03100395, 0.03301764, 0.01400447, 0.03093028, 0.02903891,\n",
       "        0.0380125 , 0.03295183, 0.03500867, 0.03700876, 0.01200223,\n",
       "        0.02003527, 0.01597285, 0.01599908, 0.01596189, 0.01296687,\n",
       "        0.01000261, 0.01000118, 0.00902224, 0.01097012, 0.01399732,\n",
       "        0.01300287, 0.03300452, 0.04900002, 0.03599787, 0.03096914,\n",
       "        0.02996278, 0.03403592, 0.02902293, 0.02100754, 0.03205252,\n",
       "        0.03799772, 0.03399777, 0.03300834, 0.03100872, 0.03405333,\n",
       "        0.03599977, 0.03999162, 0.03598928, 0.03200078, 0.04195285,\n",
       "        0.01203203, 0.01603007, 0.01202846, 0.01199126, 0.01199818,\n",
       "        0.0099957 , 0.00899887, 0.0109992 , 0.0090003 , 0.01196551,\n",
       "        0.01000452, 0.00900316, 0.00899816, 0.01000023, 0.00899696,\n",
       "        0.01300454, 0.00996757, 0.00899458, 0.01000047, 0.00899911,\n",
       "        0.00999832, 0.00903606, 0.00900173, 0.0099988 , 0.01200438,\n",
       "        0.00996852, 0.00996542, 0.00899768, 0.00900006, 0.0090313 ,\n",
       "        0.00902867, 0.01099586, 0.01499891, 0.0119679 , 0.01000333,\n",
       "        0.01202965, 0.00899982, 0.00899625, 0.01000142, 0.00996828,\n",
       "        0.01102543, 0.01102757, 0.01099873, 0.00899482, 0.01196718,\n",
       "        0.01199889, 0.01099658, 0.01103234, 0.01101136, 0.00900054,\n",
       "        0.00900173, 0.01100802, 0.00999713, 0.01099873, 0.01100373,\n",
       "        0.01000404, 0.00896692, 0.00999928, 0.00899982, 0.01096559,\n",
       "        0.00999498, 0.00900054, 0.00902987, 0.00899529, 0.00896931,\n",
       "        0.00900793, 0.01002955, 0.00899887, 0.01097107, 0.0099647 ,\n",
       "        0.00996876, 0.00999975, 0.01199675, 0.009969  , 0.01003647,\n",
       "        0.01099825, 0.01099801, 0.00900006, 0.01000404, 0.0090332 ,\n",
       "        0.0109694 , 0.00996661, 0.0100317 , 0.0110321 , 0.00999856,\n",
       "        0.01000285, 0.00999498, 0.01000166, 0.01203108, 0.0120008 ,\n",
       "        0.00996494, 0.00999761, 0.00900412, 0.00900149, 0.01100063,\n",
       "        0.00996995, 0.01303411, 0.01199389, 0.01003313, 0.00900173,\n",
       "        0.01200676, 0.00897074, 0.00904131, 0.00900483, 0.01000166,\n",
       "        0.0090282 , 0.01096463, 0.01103234, 0.01000524, 0.00896716,\n",
       "        0.00903296, 0.0110364 , 0.00903821, 0.00998974, 0.01000023,\n",
       "        0.00897455, 0.01002932, 0.00896811, 0.00899935, 0.0090065 ,\n",
       "        0.00900006, 0.00899839, 0.00896263, 0.01000142, 0.00900435,\n",
       "        0.0089972 , 0.00900292, 0.00999856, 0.00896549, 0.01403308,\n",
       "        0.00996518, 0.00899982, 0.01099968, 0.00999761, 0.00900745,\n",
       "        0.00899744, 0.00903058, 0.00999975, 0.01103544, 0.0110321 ,\n",
       "        0.00900006, 0.00996375, 0.01002645, 0.00899744, 0.00999713,\n",
       "        0.00899935, 0.00899935, 0.00899911, 0.01603651, 0.02099514,\n",
       "        0.01199889, 0.01096725, 0.01099825, 0.00896358, 0.00899744,\n",
       "        0.00996685, 0.00997186, 0.00896716, 0.00999951, 0.00997186,\n",
       "        0.01000476, 0.01000166, 0.01396871, 0.00999951, 0.0100131 ,\n",
       "        0.00996685, 0.00899792, 0.0090003 , 0.01000261, 0.00900364,\n",
       "        0.00902677, 0.00896692, 0.01100111, 0.01000214, 0.01003408,\n",
       "        0.00899529, 0.00899935, 0.00996327, 0.01000524, 0.01000595,\n",
       "        0.00899863, 0.0109911 , 0.01003385, 0.00899816, 0.00900006,\n",
       "        0.00999951, 0.00904465, 0.0089674 , 0.01003289, 0.00903201,\n",
       "        0.00900674, 0.00899887, 0.01099992, 0.00900078, 0.00899792,\n",
       "        0.0099678 , 0.01200175, 0.00900435, 0.00999832, 0.01400256,\n",
       "        0.0099678 , 0.00900006, 0.01103044, 0.01102972, 0.00900006,\n",
       "        0.00896955, 0.00999713, 0.00999808, 0.00899863, 0.01096559]),\n",
       " 'estimator': [RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier(),\n",
       "  RandomForestClassifier()],\n",
       " 'test_score': array([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 1., 1.])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "score = cross_validate(estimator=classifier, cv=cv, return_estimator=True, X=x_csp_average, y=y, scoring=\"accuracy\")\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = score[\"estimator\"][0]\n",
    "cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.28453985, -1.11264367, -0.51769977, -0.9126218 , -0.59385353,\n",
       "        -0.87488333],\n",
       "       [ 1.19902168, -0.39986554,  0.06249661, -0.29163824, -0.85538807,\n",
       "        -0.72179319],\n",
       "       [-0.10670904, -1.52099123, -0.81614722,  0.42354686, -0.60397908,\n",
       "        -0.06435189],\n",
       "       ...,\n",
       "       [-1.57051966, -1.30172233, -1.46471422, -1.73299095, -1.51230562,\n",
       "        -0.99641528],\n",
       "       [-0.89278672, -1.5037334 , -1.82430643, -0.52081341, -0.21268499,\n",
       "        -1.88205055],\n",
       "       [-1.51984772, -0.85753073, -0.76879766, -0.68484572, -0.57817211,\n",
       "        -1.71860077]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tst = data_tst.get_data()\n",
    "y_tst = data_tst.events[:,2] - 1\n",
    "\n",
    "x_csp_average_test = csp.transform(x_tst)\n",
    "x_csp_average_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = cl.predict(x_csp_average_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_tst, pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=pred, y_true=y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "0.8770833333333333\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for estimator in score[\"estimator\"]:\n",
    "    pred = estimator.predict(x_csp_average_test)\n",
    "    acc = accuracy_score(y_pred=pred, y_true=y_tst)\n",
    "    if acc > max:\n",
    "        print(acc)\n",
    "        max = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "On remarque une bonne accuracy, mais celle ci est due à la mauvaise répartition des classes, il faut donc travailler sur ce point pour espérer avoir un meilleur recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = pd.Series(y)\n",
    "y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remaques que les classes sont très disproportionnées et que le modèles à donc des difficultés à apprendre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dcd1d2511816899a74ba735f0586ad2a5252297c95097d38969d839b5b7443a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
